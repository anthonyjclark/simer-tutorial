{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Demo 4: Full Example\"\n",
        "execute:\n",
        "    echo: false\n",
        "format:\n",
        "    html:\n",
        "        css: ../_lib/WMR2D/css/main.css\n",
        "        highlight-style: pygments\n",
        "---"
      ],
      "id": "327e8bbc"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll now look at a full evolutionary robotics example. Here are the steps:\n",
        "\n",
        "1. Setup a compute environment.\n",
        "2. Create a simulation that is decoupled from evolution and visualization.\n",
        "3. Implement an evolutionary algorithm.\n",
        "4. Launch the evolutionary process and leverage parallelism.\n",
        "5. Analyze and visualize the results.\n",
        "\n",
        "## Setup\n",
        "\n",
        "I am using an HPC linux server with [Lmod](https://lmod.readthedocs.io/en/latest/) (used for environment management) and [Slurm](https://slurm.schedmd.com/documentation.html) (for workload management). Though these instructions will work pretty broadly.\n",
        "\n",
        "I use [Miniforge](https://github.com/conda-forge/miniforge) to manage my software installations. So, here is my process:\n",
        "\n",
        "```bash\n",
        "# Install or activate Miniforge\n",
        "module load miniforge3\n",
        "\n",
        "# Create a new environment\n",
        "mamba create --name simer\n",
        "\n",
        "# Install necessary packages\n",
        "mamba install pybox2d ipython pandas enlighten jupyter seaborn plotly\n",
        "\n",
        "# Save the environment for reproducibility (create both)\n",
        "conda env export --from-history > cross-platform.yml\n",
        "conda list --explicit > spec-file.txt\n",
        "\n",
        "# Create a directory for code (and a separate for data if needed)\n",
        "mkdir -p ~/simer-tutorial\n",
        "cd ~/simer-tutorial\n",
        "```\n",
        "\n",
        "Once the directory is created, I typically edit code using [VSCode](https://code.visualstudio.com/) with the [Remote - SSH](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-ssh) extension.\n",
        "\n",
        "## Simulation\n",
        "\n",
        "My WMR simulation, written in Python, largely follows the version from demos 1-3. The key is that the simulation can be constructed with the parameters we want to evolve:\n",
        "\n",
        "```python\n",
        "class WMR:\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        wheel_radius: float,\n",
        "        chassis_length: float,\n",
        "        suspension_frequency: float,\n",
        "        suspension_damping: float,\n",
        "        sensor_limit: float,\n",
        "        duration: float,\n",
        "        time_step: float,\n",
        "        visualize: bool = False,\n",
        "    ):\n",
        "    ...\n",
        "```\n",
        "\n",
        "In the evolution file, we can then simulate with:\n",
        "\n",
        "```python\n",
        "wmr = WMR(\n",
        "    wheel_radius=wheel_radius,\n",
        "    chassis_length=chassis_length,\n",
        "    suspension_frequency=suspension_frequency,\n",
        "    suspension_damping=suspension_damping,\n",
        "    sensor_limit=sensor_limit,\n",
        "    duration=DURATION,\n",
        "    time_step=TIME_STEP,\n",
        "    visualize=visualize,\n",
        ")\n",
        "```\n",
        "\n",
        "Where each of these values is computed from a genome.\n",
        "\n",
        "## Evolution\n",
        "\n",
        "Here is the basic structure of the evolutionary algorithm:\n",
        "\n",
        "\n",
        "```{mermaid}\n",
        "%%| fig-align: center\n",
        "\n",
        "flowchart LR\n",
        "    Init[Initialize] --> Eval[Evaluate]\n",
        "    Eval --> Stop{Stop?}\n",
        "    Stop --Yes--> Retn[Return]\n",
        "    Stop --No--> Sele[Select]\n",
        "    Sele --> Modi[Modify]\n",
        "    Modi --> Evl2[Evaluate]\n",
        "    Evl2 --> Comb[Combine]\n",
        "    Comb --> Stop\n",
        "```\n",
        "\n",
        "\n",
        "I like to get a bit of linting help by defining the types I'll be using:\n",
        "\n",
        "```python\n",
        "Genome = list[float]\n",
        "Fitness = namedtuple(\"Fitness\", [\"feasibility\", \"objective\"])\n",
        "Individual = tuple[Genome, Fitness]\n",
        "Population = list[Individual]\n",
        "```\n",
        "\n",
        "And also some utility function:\n",
        "\n",
        "```python\n",
        "def clamp(lo: float, hi: float, value: float) -> float: ...\n",
        "def scale(from_lo: float, from_hi: float, to_lo: float, to_hi: float, value: float) -> float: ...\n",
        "def statistics(pop: Population) -> tuple[Fitness, Fitness, Fitness]: ...\n",
        "```\n",
        "\n",
        "Now the core of our algorithm's implementation:\n",
        "\n",
        "```python\n",
        "def generate_genome() -> Genome: ...\n",
        "def simulate(...) -> Fitness: ...\n",
        "def fitness(genome: Genome, testing=False) -> tuple[Fitness, dict]: ...\n",
        "\n",
        "def initialize(size: int) -> Population: ...\n",
        "def evaluate(pop: Population, manager) -> Population: ...\n",
        "def stop(pop: Population, *, _best=[Fitness(0, 0)], _counter=[0]) -> bool: ...\n",
        "\n",
        "def tournament(pop: Population) -> Individual: ...\n",
        "def select(pop: Population) -> Population: ...\n",
        "\n",
        "def mutate_gene(gene: float) -> float: ...\n",
        "def mutate(genome: Genome) -> Genome: ...\n",
        "def modify(pop: Population) -> Population: ...\n",
        "\n",
        "def combine(original: Population, children: Population) -> Population: ...\n",
        "```\n",
        "\n",
        "And here is the main loop:\n",
        "\n",
        "```python\n",
        "population = initialize(args.population_size)\n",
        "population = evaluate(population, manager)\n",
        "\n",
        "for generation in range(args.num_generations):\n",
        "    if stop(population):\n",
        "        break\n",
        "\n",
        "    selected = select(population)\n",
        "    children = modify(selected)\n",
        "    children = evaluate(children, manager)\n",
        "    population = combine(population, children)\n",
        "```\n",
        "\n",
        "A few of my implementation specific details are bleeding through. For example, using the [enlighten](https://python-enlighten.readthedocs.io/en/stable/) progress bar manager. You can view [the full code in the repository](https://github.com/anthonyjclark/simer-tutorial/tree/main/_example).\n",
        "\n",
        "Here's a demo of the evolution script:\n",
        "\n",
        "<script id=\"asciicast-668746\" src=\"https://asciinema.org/a/668746.js\" async></script>\n",
        "\n",
        "<!-- https://asciinema.org/a/668746 -->\n",
        "\n",
        "## Launch\n",
        "\n",
        "Rarely do we want to run a single \"replicate\" of an evolutionary optimization process. Instead, we run many with different initial conditions. The script below will launch 10 trials of the evolutionary process:\n",
        "\n",
        "```bash\n",
        "# Load conda and activate an environment\n",
        "module load miniconda3\n",
        "conda activate boxcarv2\n",
        "\n",
        "POP_SIZE=100\n",
        "NUM_GENERATIONS=100\n",
        "NUM_TRIALS=10\n",
        "\n",
        "slurm_args=\"--ntasks=1 --nodes=1 --exclusive\"\n",
        "cmd=\"python wmr_evolution.py\"\n",
        "cmd_args=\"--population_size $POP_SIZE --num_generations $NUM_GENERATIONS\"\n",
        "\n",
        "set -exuo pipefail\n",
        "\n",
        "for trial in $(seq 1 $NUM_TRIALS); do\n",
        "    srun $slurm_args $cmd \"trial$trial\" $cmd_args --seed $trial &\n",
        "done\n",
        "wait\n",
        "```\n",
        "\n",
        "You can find the [full script with SLURM options here](https://github.com/anthonyjclark/simer-tutorial/blob/main/_example/run.slurm.sh).\n",
        "\n",
        "## Analyze\n",
        "\n",
        "Last, let's take a look at the results.\n",
        "\n",
        "### Visualizations\n",
        "\n",
        "I like to start with the behaviors. I have my script output the \"best\" individual from each replicate experiment. The behavior is output as a JSON log file that I can visualize with [Review](https://review.github.io/) (a tool I created for this purpose).\n",
        "\n",
        "<iframe src=\"https://review.github.io/?log=https://raw.githubusercontent.com/anthonyjclark/simer-tutorial/main/_example/data/trial5-visualization.json\" title=\"Review\" width=\"100%\" height=\"400\" style=\"display: block; margin: 0 auto;\">\n",
        "  <p>Visualization not shown because your browser does not allow use of an iframe.</p>\n",
        "</iframe>\n",
        "\n",
        "Here's a second example with a slightly different behavior:\n",
        "\n",
        "<iframe src=\"https://review.github.io/?log=https://raw.githubusercontent.com/anthonyjclark/simer-tutorial/main/_example/data/trial4-visualization.json\" title=\"Review\" width=\"100%\" height=\"400\" style=\"display: block; margin: 0 auto;\">\n",
        "  <p>Visualization not shown because your browser does not allow use of an iframe.</p>\n",
        "</iframe>\n",
        "\n",
        "Both of these are \"better\" behaviors than I was able to achieve by hand.\n",
        "\n",
        "### Evolutionary Progress\n",
        "\n",
        "Figure @fig-generations shows the fitness of the best and average individuals over generations. We can see that the best individual from each replicate improves over time. The shaded regions denote the 95% confidence interval around the average performance.\n",
        "\n",
        "The average performance (in orange) will always be a bit noisy depending on the exact algorithm. I implemented an overly simple algorithm with a lot of \"exploration\" and less \"exploitation.\"\n"
      ],
      "id": "fb2cc78f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-generations\n",
        "#| fig-cap: Generations Vs. Fitness\n",
        "\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objs as go\n",
        "import plotly.io as pio\n",
        "\n",
        "pio.templates.default = \"plotly_white\"\n",
        "\n",
        "data_dir = Path(\"../_example/data\")\n",
        "replicate_name = \"trial\"\n",
        "files = data_dir.glob(\"*-generations.csv\")\n",
        "\n",
        "partial_dfs = []\n",
        "\n",
        "for f in files:\n",
        "    trial = f.stem.split(replicate_name)[1].split(\"-\")[0]\n",
        "    df_partial = pd.read_csv(f)\n",
        "    df_partial[\"Trial\"] = trial\n",
        "\n",
        "    partial_dfs.append(df_partial)\n",
        "\n",
        "df_generations = pd.concat(partial_dfs, ignore_index=True)\n",
        "\n",
        "\n",
        "def lineplot(fig, df, x, y, title, x_label, y_label):\n",
        "    i = len(fig.data) // 3\n",
        "    line_color = px.colors.qualitative.Dark2[i]\n",
        "    # line_color = \"rgb(31, 119, 180)\"\n",
        "    c = px.colors.qualitative.Pastel2[i].split(\"(\")[1].split(\")\")[0]\n",
        "    fill_color = f\"rgba({c}, 0.3)\"\n",
        "    # fill_color = \"rgba(68, 68, 68, 0.3)\"\n",
        "\n",
        "    df_plot = df[[x, y]].groupby([x]).agg([\"mean\", \"std\", \"count\"])\n",
        "    df_plot = df_plot.droplevel(axis=1, level=0).reset_index()\n",
        "    df_plot[\"ci\"] = 1.96 * df_plot[\"std\"] / np.sqrt(df_plot[\"count\"])\n",
        "    df_plot[\"ci_lower\"] = df_plot[\"mean\"] - df_plot[\"ci\"]\n",
        "    df_plot[\"ci_upper\"] = df_plot[\"mean\"] + df_plot[\"ci\"]\n",
        "\n",
        "    fig.add_traces(\n",
        "        [\n",
        "            go.Scatter(\n",
        "                name=y,\n",
        "                x=df_plot[x],\n",
        "                y=df_plot[\"mean\"],\n",
        "                mode=\"lines\",\n",
        "                line=dict(color=line_color),\n",
        "            ),\n",
        "            go.Scatter(\n",
        "                name=\"95% CI Upper\",\n",
        "                x=df_plot[x],\n",
        "                y=df_plot[\"ci_upper\"],\n",
        "                mode=\"lines\",\n",
        "                marker=dict(color=\"#444\"),\n",
        "                line=dict(width=0),\n",
        "                showlegend=False,\n",
        "            ),\n",
        "            go.Scatter(\n",
        "                name=\"95 CI Lower\",\n",
        "                x=df_plot[x],\n",
        "                y=df_plot[\"ci_lower\"],\n",
        "                marker=dict(color=\"#444\"),\n",
        "                line=dict(width=0),\n",
        "                mode=\"lines\",\n",
        "                fillcolor=fill_color,\n",
        "                fill=\"tonexty\",\n",
        "                showlegend=False,\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "    fig.update_layout(\n",
        "        xaxis_title=x_label,\n",
        "        yaxis_title=y_label,\n",
        "        # title=title,\n",
        "        hovermode=\"x\",\n",
        "        legend=dict(\n",
        "            yanchor=\"bottom\",\n",
        "            y=0,\n",
        "            xanchor=\"right\",\n",
        "            x=0.99,\n",
        "        ),\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "lineplot(\n",
        "    fig,\n",
        "    df_generations,\n",
        "    \"Generation\",\n",
        "    \"Best Objective\",\n",
        "    \"Fitness over Generations\",\n",
        "    \"Generation\",\n",
        "    \"Fitness\",\n",
        ")\n",
        "\n",
        "lineplot(\n",
        "    fig,\n",
        "    df_generations,\n",
        "    \"Generation\",\n",
        "    \"Average Objective\",\n",
        "    \"Fitness over Generations\",\n",
        "    \"Generation\",\n",
        "    \"Fitness\",\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "id": "fig-generations",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Final Fitness Values\n"
      ],
      "id": "a2d3d40f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "files = data_dir.glob(\"*-population.csv\")\n",
        "\n",
        "partial_dfs = []\n",
        "\n",
        "for f in files:\n",
        "    trial = f.stem.split(replicate_name)[1].split(\"-\")[0]\n",
        "    df_partial = pd.read_csv(f)\n",
        "    df_partial[\"Trial\"] = trial\n",
        "\n",
        "    partial_dfs.append(df_partial)\n",
        "\n",
        "df_pop = pd.concat(partial_dfs, ignore_index=True)\n",
        "df_pop.columns = [n.replace(\"_\", \" \").replace(\"-\", \" \").title() for n in df_pop.columns]\n",
        "\n",
        "df_pop = df_pop.nlargest(int(df_pop.shape[0] * 0.05), \"Objective\")"
      ],
      "id": "c03e30ea",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I used the following objective function:\n",
        "\n",
        "$$\n",
        "f = 2 \\left(1 - \\frac{d}{d_{\\text{max}}}\\right) + 1 \\left(1 - \\frac{\\omega}{\\omega_{\\text{max}}}\\right) + \\frac{1}{2} \\left( 1 - \\text{hit} \\right) + \\frac{1}{4} \\left(1 - \\frac{r}{r_{\\text{max}}}\\right) + \\frac{1}{4} \\left(1 - \\frac{t_r}{t_{\\text{max}}}\\right)\n",
        "$$\n",
        "\n",
        "The different components are meant to:\n",
        "\n",
        "1. Minimize distance from the final target location.\n",
        "2. Minimize the final angular velocity of the wheels.\n",
        "3. Penalize hitting the wall.\n",
        "4. Minimize the wheel radius.\n",
        "5. Minimize the time taken to reach rest.\n",
        "\n",
        "This equation is pretty brittle, and with multiple objectives you would be better off using a many objective optimization algorithm, such as [Lexicase](https://direct.mit.edu/artl/article/28/4/479/112725/Lexicase-Selection-for-Multi-Task-Evolutionary).\n",
        "\n",
        "From @fig-objective, we can see that we mostly achieve our goals. It appears that there is a minimum wheel radius that is able to get over the step, and we cannot instantaneously reach the target position.\n"
      ],
      "id": "8cb2eab5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-objective\n",
        "#| fig-cap: Evolved Objectives of Top 5% of Final Populations\n",
        "\n",
        "objectives = {\n",
        "    \"Final Distance\": (0, 17),\n",
        "    \"Final Speed\": (0, 10),\n",
        "    \"Hit Wall\": (0, 1),\n",
        "    \"Wheel Radius\": (0.5, 1.5),\n",
        "    \"Index At Rest\": (0, 2008),\n",
        "}\n",
        "\n",
        "columns = objectives.keys()\n",
        "\n",
        "df_altered = df_pop[columns].copy()\n",
        "df_altered[\"Hit Wall\"] = df_pop[\"Hit Wall\"].astype(float)\n",
        "\n",
        "for name, (lo, hi) in objectives.items():\n",
        "    df_altered[name] = df_altered[name] / (hi - lo) - lo\n",
        "\n",
        "fig = px.strip(df_altered)\n",
        "\n",
        "fig.update_layout(\n",
        "    yaxis_showticklabels=False,\n",
        "    yaxis_title=\"\",\n",
        "    xaxis_title=\"\",\n",
        "    yaxis_range=[0, 1],\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "id": "fig-objective",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evolved Parameters\n",
        "\n",
        "Now we turn to the evolved parameters, shown in @fig-parameters.\n"
      ],
      "id": "9dfec6ed"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-parameters\n",
        "#| fig-cap: Evolved Parameters of Top 5% of Final Populations\n",
        "\n",
        "limits = {\n",
        "    \"Wheel Radius\": (0.5, 1.5),\n",
        "    \"Chassis Length\": (1, 4),\n",
        "    \"Suspension Frequency\": (1, 8),\n",
        "    \"Suspension Damping\": (0.3, 0.9),\n",
        "    \"Sensor Limit\": (1, 15),\n",
        "    \"Speed Max\": (0, 10),\n",
        "    \"Speed Slope\": (0, 10),\n",
        "    \"Speed Intercept\": (-20, 20),\n",
        "}\n",
        "\n",
        "columns = [f\"{name} Genome\" for name in limits.keys()]\n",
        "labels = [\"<br>\".join(name.split(\" \")[:2]) for name in columns]\n",
        "\n",
        "df_renamed = df_pop[columns]\n",
        "df_renamed.columns = labels\n",
        "\n",
        "fig = px.strip(df_renamed)\n",
        "\n",
        "fig.update_layout(\n",
        "    yaxis_showticklabels=False,\n",
        "    yaxis_title=\"\",\n",
        "    xaxis_title=\"\",\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "id": "fig-parameters",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This plot only shows the top 5% of individuals across all final replicate populations. I filtered out the lower performing individuals since I have a heavily \"exploration\"-centered algorithm.\n",
        "\n",
        "From these values, we can get a good idea of our design constraints. We can also guess that it would be good to increase the maximum possible value for suspension frequency and the sensor limit. Increasing the top speed is probably not a good idea since it will be limited by the hardware more so than the other two parameters.\n",
        "\n",
        "\n",
        "Finally, in @fig-correlations, we take a look at the correlations among parameters.\n"
      ],
      "id": "eb0d9ab7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-correlations\n",
        "#| fig-cap: Correlations among Evolved Parameters of Top 5% of Final Populations\n",
        "\n",
        "df_corr = df_renamed.corr().round(1)\n",
        "mask = np.zeros_like(df_corr, dtype=bool)\n",
        "mask[np.tril_indices_from(mask)] = True\n",
        "fig = px.imshow(df_corr.mask(~mask), text_auto=True)\n",
        "fig.show()"
      ],
      "id": "fig-correlations",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is usually a good idea to see if there are any strong tradeoffs among the parameters. For example, there is a strongly negative correlation between the speed slop and intercept."
      ],
      "id": "43f1cc0b"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}